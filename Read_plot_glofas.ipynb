{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "85900000\n",
      "RIO PARDO\n"
     ]
    }
   ],
   "source": [
    "name_data = 'discharge'\n",
    "\n",
    "# -----------------------------------------------------------------------------  \n",
    "\n",
    "# See data from station\n",
    "info_stations = pd.read_csv('../Documents/porto_alegre_stations_wwhoutid.csv')\n",
    "\n",
    "# Specify the directory path\n",
    "hist_folder_path = f'Historic_{name_data}'\n",
    "telem_folder_path = 'Telemetricas'\n",
    "\n",
    "# for index, code in enumerate(info_stations['Code']):\n",
    "\n",
    "# Set station of interest manually\n",
    "index_ = 6\n",
    "\n",
    "station_name = info_stations['Name'][index_]\n",
    "station_code = info_stations['Code'][index_]\n",
    "print('----------------------------------------------------------------------------')\n",
    "print(station_code)\n",
    "print(station_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_netcdf_summary(file_path, return_variables=None):\n",
    "\n",
    "    print(return_variables)\n",
    "    \"\"\"Prints a summary and optionally returns data for specific variables from a NetCDF file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        dataset = nc.Dataset(file_path, mode='r')\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening file: {e}\")\n",
    "        return\n",
    "\n",
    "    variable_data = {}\n",
    "\n",
    "    print(\"Global Attributes:\")\n",
    "    for attr in dataset.ncattrs():\n",
    "        print(f\"  {attr}: {dataset.getncattr(attr)}\")\n",
    "\n",
    "    print(\"\\nDimensions:\")\n",
    "    for dim, dim_obj in dataset.dimensions.items():\n",
    "        print(f\"  {dim}: length {dim_obj.size} (unlimited: {dim_obj.isunlimited()})\")\n",
    "\n",
    "    print(\"\\nVariables:\")\n",
    "    for var in dataset.variables:\n",
    "        print(f\"Variable: {var}\")\n",
    "        print(f\"  Type: {dataset.variables[var].dtype}\")\n",
    "        print(f\"  Dimensions: {dataset.variables[var].dimensions}\")\n",
    "        print(f\"  Shape: {dataset.variables[var].shape}\")\n",
    "        for attr in dataset.variables[var].ncattrs():\n",
    "            print(f\"    {attr}: {dataset.variables[var].getncattr(attr)}\")\n",
    "        if return_variables and var in return_variables:\n",
    "            variable_data[var] = dataset.variables[var][:]\n",
    "\n",
    "    if 'time' in dataset.variables:\n",
    "        T_var = dataset.variables['time']\n",
    "        T_units = T_var.units if 'units' in T_var.ncattrs() else 'No units available'\n",
    "        T_data = T_var[:]\n",
    "        print(f\"\\nT units: {T_units} Data: {T_data}\")\n",
    "\n",
    "    dataset.close()\n",
    "\n",
    "    if return_variables:\n",
    "        print('retorna!')\n",
    "        return variable_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_station(folder_path, file_name):\n",
    "    \n",
    "    full_path = os.path.join(folder_path, f'{file_name}.txt')\n",
    "    try:\n",
    "        # Load observation data from a text file\n",
    "        # Specify -99999 and -1 as NaN values\n",
    "        df = pd.read_table(full_path, delim_whitespace=True, na_values=[-99999, -1])\n",
    "\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No data: {full_path}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if file is not found\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_files_and_dates(directory_path):\n",
    "    \"\"\"Checks if the directory exists and returns a DataFrame containing filenames and their corresponding dates.\"\"\"\n",
    "    if os.path.exists(directory_path):\n",
    "        file_list = os.listdir(directory_path)\n",
    "        file_dates = [file.split('_')[-1].split('.')[0] for file in file_list]\n",
    "        file_dates = [datetime.strptime(date, '%Y%m%d%H') for date in file_dates]\n",
    "        file_data = pd.DataFrame({\n",
    "            'File Name': file_list,\n",
    "            'Date': file_dates\n",
    "        }).sort_values(by='Date').reset_index(drop=True)\n",
    "        return file_data\n",
    "    else:\n",
    "        print(f\"The directory '{directory_path}' does not exist.\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_glofas_data(file_data, station_code):\n",
    "    \n",
    "    forecast_dict = {}  # Use a dictionary to store the data by issue_date\n",
    "\n",
    "    # Iterate over the forecast files\n",
    "    for forecast in range(len(file_data)):\n",
    "        filename = file_data['File Name'].loc[forecast]\n",
    "        file_path = os.path.join('glofas_v4.0_forecasts_20240505-20240510/', filename)\n",
    "        \n",
    "        # Open the dataset\n",
    "        dataset = nc.Dataset(file_path, mode='r')\n",
    "        \n",
    "        # Extract necessary variables from the dataset\n",
    "        variables = {var: dataset.variables[var][:] for var in dataset.variables}\n",
    "        ensemble = variables['ensemble']\n",
    "        dis24 = variables['dis24']\n",
    "        \n",
    "        station_index = int(np.where(variables['code'] == station_code)[0])\n",
    "\n",
    "        issue_date = file_data['Date'].loc[forecast]\n",
    "        \n",
    "        # Ensure issue_date is aware of timezone\n",
    "        if issue_date.tzinfo is None or issue_date.tzinfo.utcoffset(issue_date) is None:\n",
    "            issue_date = issue_date.replace(tzinfo=timezone.utc)\n",
    "        \n",
    "        start_date = issue_date + timedelta(days=0.5)  # Adjust to 12:00\n",
    "        \n",
    "        # Close the dataset\n",
    "        dataset.close()\n",
    "\n",
    "        # Extract data for the station\n",
    "        dis24_station = dis24[:, station_index, :]  # dShape: (30, 11, 51)\n",
    "        \n",
    "        print(dis24_station)\n",
    "        dis24_mean = np.mean(dis24_station, axis=1)  # Daily mean\n",
    "\n",
    "        # Create a daily time series starting from the start date\n",
    "        time = [start_date + timedelta(days=i) for i in range(30)]  # Assumes 30 days of data\n",
    "        \n",
    "        # Store data in the dictionary using the issue_date as the key\n",
    "        forecast_dict[issue_date] = {\n",
    "            'time': time,\n",
    "            'dis24_ensem': dis24_station,\n",
    "            'dis24_station': dis24_mean,\n",
    "            'start_date': start_date\n",
    "        }\n",
    "\n",
    "    return forecast_dict, station_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_glofas_forecasts(forecast_dict, df_obs, station_name, threshold_data, name_data, glofas_index):\n",
    "    \n",
    "    f = 0\n",
    "\n",
    "    # Iterate over the forecasts stored in the dictionary\n",
    "    for issue_date, issue in forecast_dict.items():\n",
    "        f += 1\n",
    "        time = pd.to_datetime(issue['time'])  # Convert to datetime\n",
    "\n",
    "        dis24_station = issue['dis24_ensem']\n",
    "        dis24_mean = issue['dis24_station']\n",
    "        issue_date = pd.to_datetime(issue_date)  # Convert issue_date to datetime if it's not already\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        for i in range(dis24_station.shape[1]):\n",
    "            plt.plot(time, dis24_station[:, i], color='grey', alpha=0.2)\n",
    "\n",
    "        plt.plot(time, dis24_mean, color='blue', linewidth=2, alpha=0.8, label='Ensemble Mean')\n",
    "        \n",
    "        # Normalize the observed data 'date' column to midnight\n",
    "        df_obs['date'] = pd.to_datetime(df_obs['date']).dt.normalize()\n",
    "\n",
    "        plt.plot(df_obs['date'], df_obs[name_data], color='black', label='Observed Data')\n",
    "        \n",
    "        plt.xlabel('Date (2024)')\n",
    "        plt.ylabel('Discharge (m³/s)')\n",
    "        # plt.title(f'GloFAS 24-hour Discharge Forecast for {station_name} Station')\n",
    "        plt.xlim(time[0] - timedelta(days=5), time[-1])\n",
    "        plt.ylim(0,30000)\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=2))\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.grid(True, color='grey', alpha=0.2, which='both', linestyle='-', axis='x')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.axvline(x=issue_date, color='black', linestyle='--', label='Date of issue')\n",
    "        \n",
    "        # Draw threshold lines\n",
    "        for key, value in threshold_data.items():\n",
    "            plt.axhline(y=value[glofas_index], color='red' if key == 'rl50' else 'orange', linewidth=2, alpha=0.4, label=f'{key.upper()} Threshold')\n",
    "\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.savefig(f'Figures/{station_name}_GloFAS_{f}.png', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              File Name       Date\n",
      "0   glofas_v4.0_forecasts_2024041500.nc 2024-04-15\n",
      "1   glofas_v4.0_forecasts_2024041600.nc 2024-04-16\n",
      "2   glofas_v4.0_forecasts_2024041700.nc 2024-04-17\n",
      "3   glofas_v4.0_forecasts_2024041800.nc 2024-04-18\n",
      "4   glofas_v4.0_forecasts_2024041900.nc 2024-04-19\n",
      "5   glofas_v4.0_forecasts_2024042000.nc 2024-04-20\n",
      "6   glofas_v4.0_forecasts_2024042100.nc 2024-04-21\n",
      "7   glofas_v4.0_forecasts_2024042200.nc 2024-04-22\n",
      "8   glofas_v4.0_forecasts_2024042300.nc 2024-04-23\n",
      "9   glofas_v4.0_forecasts_2024042400.nc 2024-04-24\n",
      "10  glofas_v4.0_forecasts_2024042500.nc 2024-04-25\n",
      "11  glofas_v4.0_forecasts_2024042600.nc 2024-04-26\n",
      "12  glofas_v4.0_forecasts_2024042700.nc 2024-04-27\n",
      "13  glofas_v4.0_forecasts_2024042800.nc 2024-04-28\n",
      "14  glofas_v4.0_forecasts_2024042900.nc 2024-04-29\n",
      "15  glofas_v4.0_forecasts_2024043000.nc 2024-04-30\n",
      "16  glofas_v4.0_forecasts_2024050100.nc 2024-05-01\n",
      "17  glofas_v4.0_forecasts_2024050200.nc 2024-05-02\n",
      "18  glofas_v4.0_forecasts_2024050300.nc 2024-05-03\n",
      "19  glofas_v4.0_forecasts_2024050400.nc 2024-05-04\n",
      "20  glofas_v4.0_forecasts_2024050500.nc 2024-05-05\n",
      "21  glofas_v4.0_forecasts_2024050600.nc 2024-05-06\n",
      "22  glofas_v4.0_forecasts_2024050700.nc 2024-05-07\n",
      "23  glofas_v4.0_forecasts_2024050800.nc 2024-05-08\n",
      "24  glofas_v4.0_forecasts_2024050900.nc 2024-05-09\n",
      "25  glofas_v4.0_forecasts_2024051000.nc 2024-05-10\n"
     ]
    }
   ],
   "source": [
    "# See files from system\n",
    "directory_path = 'glofas_v4.0_forecasts_20240505-20240510/'\n",
    "file_data = list_files_and_dates(directory_path)\n",
    "if file_data is not None:\n",
    "    print(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Global Attributes:\n",
      "\n",
      "Dimensions:\n",
      "  stats: length 11 (unlimited: False)\n",
      "  ensemble: length 51 (unlimited: False)\n",
      "  time: length 30 (unlimited: False)\n",
      "  nchar: length 200 (unlimited: False)\n",
      "\n",
      "Variables:\n",
      "Variable: time\n",
      "  Type: float64\n",
      "  Dimensions: ('time',)\n",
      "  Shape: (30,)\n",
      "    long_name: time\n",
      "    standard_name: time\n",
      "    calendar: standard\n",
      "    axis: T\n",
      "    units: hours since 2024-04-04 00:00:00\n",
      "Variable: ensemble\n",
      "  Type: int16\n",
      "  Dimensions: ('ensemble',)\n",
      "  Shape: (51,)\n",
      "    units: -\n",
      "    long_name: ensemble members\n",
      "Variable: priority\n",
      "  Type: int16\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Priority rank\n",
      "Variable: name\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the station\n",
      "Variable: river\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the river\n",
      "Variable: code\n",
      "  Type: int32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Station code\n",
      "Variable: lat\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: latitude\n",
      "Variable: lon\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: longitude\n",
      "Variable: city\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the city\n",
      "Variable: glon\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_east\n",
      "    long_name: glofas longitude\n",
      "Variable: glat\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: glofas latitude\n",
      "Variable: garea\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: km2\n",
      "    long_name: glofas upstream area\n",
      "Variable: dis24\n",
      "  Type: float64\n",
      "  Dimensions: ('time', 'stats', 'ensemble')\n",
      "  Shape: (30, 11, 51)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: 0-1\n",
      "    long_name: GloFAS 24-hour mean discharge\n",
      "\n",
      "T units: hours since 2024-04-04 00:00:00 Data: [ 24.  48.  72.  96. 120. 144. 168. 192. 216. 240. 264. 288. 312. 336.\n",
      " 360. 384. 408. 432. 456. 480. 504. 528. 552. 576. 600. 624. 648. 672.\n",
      " 696. 720.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = file_data['File Name'].loc[0]\n",
    "file_path = os.path.join(directory_path, filename)\n",
    "print_netcdf_summary(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rl1.5', 'rl50']\n",
      "Global Attributes:\n",
      "\n",
      "Dimensions:\n",
      "  stats: length 11 (unlimited: False)\n",
      "  nchar: length 200 (unlimited: False)\n",
      "\n",
      "Variables:\n",
      "Variable: priority\n",
      "  Type: int16\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Priority rank\n",
      "Variable: name\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the station\n",
      "Variable: river\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the river\n",
      "Variable: code\n",
      "  Type: int32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Station code\n",
      "Variable: lat\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: latitude\n",
      "Variable: lon\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: longitude\n",
      "Variable: city\n",
      "  Type: <class 'str'>\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: -\n",
      "    long_name: Name of the city\n",
      "Variable: glon\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_east\n",
      "    long_name: glofas longitude\n",
      "Variable: glat\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: degrees_north\n",
      "    long_name: glofas latitude\n",
      "Variable: garea\n",
      "  Type: float32\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    units: km2\n",
      "    long_name: glofas upstream area\n",
      "Variable: rl1.5\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 1.5-year flood threshold\n",
      "Variable: rl2\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 2-year flood threshold\n",
      "Variable: rl5\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 5-year flood threshold\n",
      "Variable: rl10\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 10-year flood threshold\n",
      "Variable: rl20\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 20-year flood threshold\n",
      "Variable: rl50\n",
      "  Type: float64\n",
      "  Dimensions: ('stats',)\n",
      "  Shape: (11,)\n",
      "    _FillValue: 1e+20\n",
      "    least_significant_digit: 2\n",
      "    units: m3/s\n",
      "    long_name: GloFAS 50-year flood threshold\n",
      "retorna!\n"
     ]
    }
   ],
   "source": [
    "# See general caracteristics of some nectdf\n",
    "file_path = 'thresholds.nc'\n",
    "\n",
    "threshold_vars = ['rl1.5', 'rl50']\n",
    "threshold_data = print_netcdf_summary(file_path, return_variables=threshold_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "87450004\n",
      "CAIS MAUÁ C6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingri\\AppData\\Local\\Temp\\ipykernel_51036\\2608100217.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_table(full_path, delim_whitespace=True, na_values=[-99999, -1])\n",
      "C:\\Users\\ingri\\AppData\\Local\\Temp\\ipykernel_51036\\1659782673.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  station_index = int(np.where(variables['code'] == station_code)[0])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MaskedArray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m file_data \u001b[38;5;241m=\u001b[39m list_files_and_dates(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglofas_v4.0_forecasts_20240505-20240510/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m df_telem \u001b[38;5;241m=\u001b[39m read_station(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Telemetry\u001b[39m\u001b[38;5;124m'\u001b[39m, station_code)\n\u001b[1;32m---> 23\u001b[0m processed_data, glofas_index \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_glofas_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Save the processed data to a file\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_glofas_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m, in \u001b[0;36mprocess_glofas_data\u001b[1;34m(file_data, station_code)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Extract data for the station\u001b[39;00m\n\u001b[0;32m     32\u001b[0m dis24_station \u001b[38;5;241m=\u001b[39m dis24[:, station_index, :]  \u001b[38;5;66;03m# dShape: (30, 11, 51)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdis24_station\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m())\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(dis24_station)\n\u001b[0;32m     37\u001b[0m dis24_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(dis24_station, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Daily mean\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaskedArray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "\n",
    "name_data = 'discharge'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Read data from station\n",
    "info_stations = pd.read_csv('../Documents/porto_alegre_stations_wwhoutid.csv')\n",
    "\n",
    "# Specify the directory paths\n",
    "hist_folder_path = f'Historic_{name_data}'\n",
    "telem_folder_path = 'Telemetricas'\n",
    "\n",
    "# Loop through each station using the 'Code' column\n",
    "for index, row in info_stations.iterrows():\n",
    "    station_name = row['Name']\n",
    "    station_code = row['Code']\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print(station_code)\n",
    "    print(station_name)\n",
    "\n",
    "    if threshold_data:\n",
    "        file_data = list_files_and_dates('glofas_v4.0_forecasts_20240505-20240510/')\n",
    "        df_telem = read_station('../Telemetry', station_code)\n",
    "\n",
    "        processed_data, glofas_index = process_glofas_data(file_data, station_code)\n",
    "\n",
    "        # Save the processed data to a file\n",
    "        with open(f'data_glofas_{station_code}.pkl', 'wb') as file:\n",
    "            pickle.dump(processed_data, file)\n",
    "\n",
    "        # Plot the forecasts\n",
    "        plot_glofas_forecasts(processed_data, df_telem, station_name, threshold_data, name_data, glofas_index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
